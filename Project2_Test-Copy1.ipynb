{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the orginal Dataset, Then re run and and scaling and splitting in order to balancec and clean data\n",
    "\n",
    "## Step 1, 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "# Found Data Set\n",
    "# Generally This dataset is about Econmic Freedoms in the world\n",
    "df = pd.read_csv('efw_cc.csv')\n",
    "dataframe_copy = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_copy.loc[dataframe_copy['ECONOMIC FREEDOM'] > 5, 'Econ_Freedom_label'] = '1' # Economic Freedom is above 5\n",
    "dataframe_copy.loc[dataframe_copy['ECONOMIC FREEDOM'] <= 5, 'Econ_Freedom_label'] = '0'# Economic Freedom is between 0 and 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Orginal Shape of DataFrame (3726, 36) \n",
      "Shape of dataframe after dropping values that are NA after Categorizing predictor: (3003, 37)\n"
     ]
    }
   ],
   "source": [
    "# I dropped all the rows that are NA in the Predicting categories label (Econ_Freedom_label)\n",
    "dataframe_copy2 = dataframe_copy.dropna(subset = [\"Econ_Freedom_label\"], inplace=False)\n",
    "print(\"\\nOrginal Shape of DataFrame\", df.shape, \"\\nShape of dataframe after dropping values that are NA after Categorizing predictor:\", dataframe_copy2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>ISO_code</th>\n",
       "      <th>countries</th>\n",
       "      <th>ECONOMIC FREEDOM</th>\n",
       "      <th>rank</th>\n",
       "      <th>quartile</th>\n",
       "      <th>1a_government_consumption</th>\n",
       "      <th>1b_transfers</th>\n",
       "      <th>1c_gov_enterprises</th>\n",
       "      <th>1d_top_marg_tax_rate</th>\n",
       "      <th>...</th>\n",
       "      <th>3_sound_money</th>\n",
       "      <th>4a_tariffs</th>\n",
       "      <th>4b_regulatory_trade_barriers</th>\n",
       "      <th>4c_black_market</th>\n",
       "      <th>4d_control_movement_capital_ppl</th>\n",
       "      <th>4_trade</th>\n",
       "      <th>5a_credit_market_reg</th>\n",
       "      <th>5b_labor_market_reg</th>\n",
       "      <th>5c_business_reg</th>\n",
       "      <th>5_regulation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>ALB</td>\n",
       "      <td>Albania</td>\n",
       "      <td>7.54</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.232353</td>\n",
       "      <td>7.509902</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.553657</td>\n",
       "      <td>8.963556</td>\n",
       "      <td>7.489905</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>6.406138</td>\n",
       "      <td>8.214900</td>\n",
       "      <td>7.098562</td>\n",
       "      <td>6.916278</td>\n",
       "      <td>6.705863</td>\n",
       "      <td>6.906901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>DZA</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>4.99</td>\n",
       "      <td>159.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.150000</td>\n",
       "      <td>7.817129</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>...</td>\n",
       "      <td>7.253894</td>\n",
       "      <td>6.872533</td>\n",
       "      <td>2.481294</td>\n",
       "      <td>5.56391</td>\n",
       "      <td>1.590362</td>\n",
       "      <td>4.127025</td>\n",
       "      <td>5.100509</td>\n",
       "      <td>5.029513</td>\n",
       "      <td>5.676956</td>\n",
       "      <td>5.268992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016</td>\n",
       "      <td>AGO</td>\n",
       "      <td>Angola</td>\n",
       "      <td>5.17</td>\n",
       "      <td>155.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>8.886739</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>...</td>\n",
       "      <td>5.606605</td>\n",
       "      <td>6.989244</td>\n",
       "      <td>2.024949</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>2.044823</td>\n",
       "      <td>5.264754</td>\n",
       "      <td>7.064905</td>\n",
       "      <td>4.560325</td>\n",
       "      <td>4.930271</td>\n",
       "      <td>5.518500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>ARG</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>4.84</td>\n",
       "      <td>160.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.335294</td>\n",
       "      <td>6.048930</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.614336</td>\n",
       "      <td>6.421600</td>\n",
       "      <td>4.811105</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>4.697482</td>\n",
       "      <td>3.982547</td>\n",
       "      <td>5.419820</td>\n",
       "      <td>5.151405</td>\n",
       "      <td>5.535831</td>\n",
       "      <td>5.369019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>ARM</td>\n",
       "      <td>Armenia</td>\n",
       "      <td>7.57</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.264706</td>\n",
       "      <td>7.748532</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.521940</td>\n",
       "      <td>8.547556</td>\n",
       "      <td>7.194410</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>6.830998</td>\n",
       "      <td>8.143241</td>\n",
       "      <td>9.102046</td>\n",
       "      <td>6.234630</td>\n",
       "      <td>6.797530</td>\n",
       "      <td>7.378069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3721</th>\n",
       "      <td>1970</td>\n",
       "      <td>VEN</td>\n",
       "      <td>Venezuela</td>\n",
       "      <td>7.18</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.602003</td>\n",
       "      <td>9.827430</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>9.713677</td>\n",
       "      <td>8.066667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.688889</td>\n",
       "      <td>9.679680</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.312277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3722</th>\n",
       "      <td>1970</td>\n",
       "      <td>VNM</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3723</th>\n",
       "      <td>1970</td>\n",
       "      <td>YEM</td>\n",
       "      <td>Yemen, Rep.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3724</th>\n",
       "      <td>1970</td>\n",
       "      <td>ZMB</td>\n",
       "      <td>Zambia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.448131</td>\n",
       "      <td>9.105430</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5.133689</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.327327</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3725</th>\n",
       "      <td>1970</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.806922</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5.036667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.20000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3726 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      year ISO_code    countries  ECONOMIC FREEDOM   rank  quartile  \\\n",
       "0     2016      ALB      Albania              7.54   34.0       1.0   \n",
       "1     2016      DZA      Algeria              4.99  159.0       4.0   \n",
       "2     2016      AGO       Angola              5.17  155.0       4.0   \n",
       "3     2016      ARG    Argentina              4.84  160.0       4.0   \n",
       "4     2016      ARM      Armenia              7.57   29.0       1.0   \n",
       "...    ...      ...          ...               ...    ...       ...   \n",
       "3721  1970      VEN    Venezuela              7.18   10.0       1.0   \n",
       "3722  1970      VNM      Vietnam               NaN    NaN       NaN   \n",
       "3723  1970      YEM  Yemen, Rep.               NaN    NaN       NaN   \n",
       "3724  1970      ZMB       Zambia               NaN    NaN       NaN   \n",
       "3725  1970      ZWE     Zimbabwe               NaN    NaN       NaN   \n",
       "\n",
       "      1a_government_consumption  1b_transfers  1c_gov_enterprises  \\\n",
       "0                      8.232353      7.509902                 8.0   \n",
       "1                      2.150000      7.817129                 0.0   \n",
       "2                      7.600000      8.886739                 0.0   \n",
       "3                      5.335294      6.048930                 6.0   \n",
       "4                      7.264706      7.748532                 8.0   \n",
       "...                         ...           ...                 ...   \n",
       "3721                   6.602003      9.827430                 7.0   \n",
       "3722                        NaN           NaN                 NaN   \n",
       "3723                        NaN           NaN                 NaN   \n",
       "3724                   3.448131      9.105430                 0.0   \n",
       "3725                   7.806922           NaN                 2.0   \n",
       "\n",
       "      1d_top_marg_tax_rate  ...  3_sound_money  4a_tariffs  \\\n",
       "0                      8.0  ...       9.553657    8.963556   \n",
       "1                      4.5  ...       7.253894    6.872533   \n",
       "2                      9.5  ...       5.606605    6.989244   \n",
       "3                      4.0  ...       5.614336    6.421600   \n",
       "4                      5.0  ...       9.521940    8.547556   \n",
       "...                    ...  ...            ...         ...   \n",
       "3721                   NaN  ...       9.713677    8.066667   \n",
       "3722                   NaN  ...            NaN         NaN   \n",
       "3723                   NaN  ...            NaN         NaN   \n",
       "3724                   NaN  ...       5.133689         NaN   \n",
       "3725                   NaN  ...       5.036667         NaN   \n",
       "\n",
       "      4b_regulatory_trade_barriers  4c_black_market  \\\n",
       "0                         7.489905         10.00000   \n",
       "1                         2.481294          5.56391   \n",
       "2                         2.024949         10.00000   \n",
       "3                         4.811105          0.00000   \n",
       "4                         7.194410         10.00000   \n",
       "...                            ...              ...   \n",
       "3721                           NaN         10.00000   \n",
       "3722                           NaN              NaN   \n",
       "3723                           NaN              NaN   \n",
       "3724                           NaN          0.00000   \n",
       "3725                           NaN          7.20000   \n",
       "\n",
       "      4d_control_movement_capital_ppl   4_trade  5a_credit_market_reg  \\\n",
       "0                            6.406138  8.214900              7.098562   \n",
       "1                            1.590362  4.127025              5.100509   \n",
       "2                            2.044823  5.264754              7.064905   \n",
       "3                            4.697482  3.982547              5.419820   \n",
       "4                            6.830998  8.143241              9.102046   \n",
       "...                               ...       ...                   ...   \n",
       "3721                         8.000000  8.688889              9.679680   \n",
       "3722                              NaN       NaN                   NaN   \n",
       "3723                              NaN       NaN                   NaN   \n",
       "3724                         2.000000       NaN              7.327327   \n",
       "3725                              NaN       NaN                   NaN   \n",
       "\n",
       "      5b_labor_market_reg  5c_business_reg  5_regulation  \n",
       "0                6.916278         6.705863      6.906901  \n",
       "1                5.029513         5.676956      5.268992  \n",
       "2                4.560325         4.930271      5.518500  \n",
       "3                5.151405         5.535831      5.369019  \n",
       "4                6.234630         6.797530      7.378069  \n",
       "...                   ...              ...           ...  \n",
       "3721                  NaN              NaN      5.312277  \n",
       "3722                  NaN              NaN           NaN  \n",
       "3723                  NaN              NaN           NaN  \n",
       "3724                  NaN              NaN           NaN  \n",
       "3725                  NaN              NaN           NaN  \n",
       "\n",
       "[3726 rows x 36 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataframe_copy2.drop(['ECONOMIC FREEDOM', 'Econ_Freedom_label', 'ISO_code', 'countries'], axis = 1)\n",
    "y = dataframe_copy2.Econ_Freedom_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-37-96832b8c2d2e>, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-37-96832b8c2d2e>\"\u001b[1;36m, line \u001b[1;32m9\u001b[0m\n\u001b[1;33m    ...      X_train, X_test = X[train_index], X[test_index]\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.5, random_state=0)\n",
    "sss.get_n_splits(X, y)\n",
    "print(sss)\n",
    "StratifiedShuffleSplit(n_splits=1, random_state=0, ...)\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "   print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "...      X_train, X_test = X[train_index], X[test_index]\n",
    "...     y_train, y_test = y[train_index], y[test_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedShuffleSplit(n_splits=1, random_state=42, test_size=0.2,\n",
      "            train_size=None)\n",
      "TRAIN: [  96  578 2560 ...  534 1296   54] TEST: [2562 1587 2094 2844  312  128 2936 2611 1234  887 2157 2173 2775 2529\n",
      " 2730  453 1119 2912  371 2595 1972 1412  969 1685 1978 2688 1879    6\n",
      " 1718 1907 1310 2601  743 2878  289  463  885 2477 1103 2310 1210 1833\n",
      "   57 1106  847 1953  648 2692  747 1670   52 2501 2632 1797  236 2755\n",
      " 1889 2374 1345  680 1529  983 2152 2073 1300  373  243  861 2279   84\n",
      " 2430  884 1133 2112  801  829  794   44  727 2015 1265 2790  156 2818\n",
      " 2972 2816 2065 1445 2976 1561 2660 2433  514  140 1643 2664 2998  331\n",
      " 2585 1484 2710 1439 1501 2962  120  563 2779  197 2296 1748 2893 1373\n",
      " 1167  596 1170 1580 2075 2485 2855  293 1668  136 2793 1528 1451   37\n",
      "  581 2066  994 1285 2422 2641  856 1742 2405 1340  960  929 1749 1577\n",
      "   21 1046  546 1198 1859  883  544  791 1163 1050 2673 2952  858 1324\n",
      " 2508 1609 1271 2034  954  762 1472  242  387 2956 2491  538   40 1553\n",
      " 1723 1981 1263 1008 1992 1329  545 1554 1302 2248 1601 2877   11 1636\n",
      "  684   38  804   48  713 2135 1259 1635 1935 2245  704 2513   92 1190\n",
      " 1858 2902 1400 2332 1087 1966 2003  428 1489 1715   93  956 1902  783\n",
      " 1377 2709 2278 1906  879 1987 2352 2145 1260 1517 2260 1603 2865 1403\n",
      "  717  212 1698 2880  465 2483  701 2971 2911  870  990 1850 2224 1028\n",
      " 2801   42 2778 1776  695 2835 1806 1014 1033 2565  602 2306 1202 2561\n",
      "  489 2169  117 3001  641 1693 1383 1394 2553  171  964 2736 2713 2406\n",
      " 2023 1898 1156 1004 2910  240 2121  355  251  450   95 2263 2244  404\n",
      " 2494  580 2922 1975 1423 1938 1697 1979 2857  347  492 1419  273 1361\n",
      " 1425 1790   62 1192 1829 2466  916  955 2600 2694 1254 1186 1294 2999\n",
      " 2939 1242  938 1523  732   70   13 2182  718 1197 1752 1291  403  254\n",
      " 2211 1960  863 2670 1406 2615 2336  113 2751 2964  276  224 2058 2741\n",
      "  681 2627 1287 2409 2774  277 1834  258 1274 1934 2450  486 2958  201\n",
      "  525 2131  755 2819 2886  533 2583 1699  560  557  115 1770 2060  520\n",
      "  257 2571  673 2945 1160 2832 2890  503  993 2300 1930  660  918  433\n",
      " 2200 2537  906 1837  933 2019 2941 2625 2172 1304  769 1354 1900 1532\n",
      " 1920 2090 1617    7 2327  536 2046 2514   81 1851 2116 1989 1408 2482\n",
      "  506  141 2442  119 1590 1209 1105  710 2734  370  332 2663 2662 1737\n",
      "  649  789 1592 1236  694 2207 2808 2516 2833 1630  386  232 1068 1387\n",
      " 1298 1521 1658  472  599 1185 2077 1381 2088  793   77 1917 1328 2324\n",
      "  928  158  572  770  650 1633  746 1208 1471 1786 1701   29 2240 2691\n",
      " 1496  122 1053 1257  264  758  109  178 1464 2769  558  866 1611  663\n",
      " 2378 1903 1703  469 2705 1831 2179  420 2689 1443  699    5  658 1758\n",
      " 2868 1069  517 1181  806 2231 2465 1514 1745 1682  910 1102 1073 2726\n",
      " 1214 1250 2788 1602  552   76 1733 1928  411 2032    3 2236  902  626\n",
      "  647   68 1915 1764   49  210  146 1142  383 2360 2717 1064 2316 1862\n",
      " 2067 1211  830  494  930 2830 2527   64 2589 2820 2246 2913 1398 2810\n",
      " 2777 1121 2343  412 1430 1704  562 2985 2722 2286  378  399 1544 2591\n",
      " 2054 2228 2226 2843 2181 2377  591 1057 1550  231  531 2081  348 2030\n",
      "  780 1756 2979  753 1182 2906 2614 2270 2858 1374 1117 2299 2669  415\n",
      "  914  269  815 2255 2588 2194  935 1066  738 2253  618 2167 1753]\n"
     ]
    }
   ],
   "source": [
    "X_array = X.to_numpy()\n",
    "y_array = y.to_numpy()\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, random_state = 42)\n",
    "split.get_n_splits(X_array, y_array)\n",
    "print(split)\n",
    "for train_index , test_index in split.split(X_array, y_array):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X_array[train_index], X_array[test_index]\n",
    "    y_train, y_test = y_array[train_index] , y_array[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Value Spread\n",
      " 1    2144\n",
      "0     258\n",
      "Name: Econ_Freedom_label, dtype: int64 \n",
      "Test Value Spread\n",
      " 1    537\n",
      "0     64\n",
      "Name: Econ_Freedom_label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify = y)\n",
    "print(\"\\nTrain Value Spread\\n\", y_train.value_counts(),\n",
    "\"\\nTest Value Spread\\n\", y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.01600000e+03, 8.00000000e+00, 1.00000000e+00, ...,\n",
       "        6.35542380e+00, 7.58697598e+00, 7.74757431e+00],\n",
       "       [2.01300000e+03, 1.38000000e+02, 4.00000000e+00, ...,\n",
       "        3.03189256e+00, 5.92884935e+00, 5.56945249e+00],\n",
       "       [1.99000000e+03, 4.50000000e+01, 2.00000000e+00, ...,\n",
       "                   nan,            nan, 7.48266335e+00],\n",
       "       ...,\n",
       "       [2.01300000e+03, 1.04000000e+02, 3.00000000e+00, ...,\n",
       "        5.91644597e+00, 6.41313310e+00, 6.62896738e+00],\n",
       "       [2.00800000e+03, 9.20000000e+01, 3.00000000e+00, ...,\n",
       "        7.28965445e+00, 4.86167650e+00, 6.17778638e+00],\n",
       "       [2.01600000e+03, 2.00000000e+01, 1.00000000e+00, ...,\n",
       "        7.43924995e+00, 8.18673569e+00, 7.98643966e+00]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot concatenate object of type '<class 'numpy.ndarray'>'; only Series and DataFrame objs are valid",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-ae02a4a1e63b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdataframe_correlation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdataframe_copy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ECONOMIC FREEDOM'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    283\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIndexes\u001b[0m \u001b[0mhave\u001b[0m \u001b[0moverlapping\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m     \"\"\"\n\u001b[1;32m--> 285\u001b[1;33m     op = _Concatenator(\n\u001b[0m\u001b[0;32m    286\u001b[0m         \u001b[0mobjs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    368\u001b[0m                     \u001b[1;34m\"only Series and DataFrame objs are valid\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m                 )\n\u001b[1;32m--> 370\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m             \u001b[1;31m# consolidate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot concatenate object of type '<class 'numpy.ndarray'>'; only Series and DataFrame objs are valid"
     ]
    }
   ],
   "source": [
    "dataframe_correlation = pd.concat([dataframe_copy['ECONOMIC FREEDOM'],X_train], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = dataframe_correlation.corr()\n",
    "corr_matrix_specific = np.abs(corr_matrix['ECONOMIC FREEDOM'])\n",
    "top_correlations = corr_matrix_specific.sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_correlations = top_correlations['4_trade':'4b_regulatory_trade_barriers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_index = chosen_correlations.index\n",
    "X_train_corr = X_train.loc[:,correlation_index]\n",
    "X_test_corr = X_test.loc[:,correlation_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler() \n",
    "scaler.fit(X_train_corr)\n",
    "X_train_scaled = pd.DataFrame(scaler.transform(X_train_corr),columns = X_train_corr.columns)  \n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test_corr),columns = X_test_corr.columns)\n",
    "\n",
    "#print(\"\\nShape of Training set:\", X_train_scaled.shape, '\\nShape of Testing Set:', X_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_scaled.copy()\n",
    "X_test = X_test_scaled.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "training_set = pd.concat([X_train, y_train], axis = 1)\n",
    "sns.set_theme(style=\"ticks\", color_codes=True)\n",
    "\n",
    "sns.catplot(x=\"Econ_Freedom_label\", y=\"4_trade\", data=training_set);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is clearly a categorical variable so it is either going to be I would consider this to binary, the distirbution based upon jus the training set it would appear that this is a binomial distribution just becasue of the fact that it is predicting either 0 or a 1. Later on if there were more variables to identify this would notion would change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### I ran into some errors which wouldn't let me use f1 as a scorer, becasue it wasnt able to attribute the positive label aka yes or no of the prediction, So I modiified the F1 scorer to make it so that 1 is yes and 0 is no\n",
    "###### 1 = greater than 5, 0 is less than or equal to 5. So in other words is the value above 5 Yes everythiing else no. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KNN Optimized\n",
      "\n",
      "\n",
      "Train Accuracy:  0.9783513738551207\n",
      "\n",
      "Test Accuracy:  0.9717138103161398\n",
      "\n",
      "Test - No. Of Correct Predictions 584.0 / 601\n",
      "\n",
      "Test Confusion Matrix:\n",
      "[[ 53  11]\n",
      " [  6 531]]\n",
      "\n",
      "Test Precision = 0.971037\n",
      "Test Recall = 0.971714\n",
      "Test F1 Score = 0.971204\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.83      0.86        64\n",
      "           1       0.98      0.99      0.98       537\n",
      "\n",
      "    accuracy                           0.97       601\n",
      "   macro avg       0.94      0.91      0.92       601\n",
      "weighted avg       0.97      0.97      0.97       601\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "knn_base = KNeighborsClassifier()\n",
    "knn_base.fit(X_train , y_train)\n",
    "prediction = knn_base.predict(X_test)\n",
    "training_predictioin = knn_base.predict(X_train)\n",
    "\n",
    "print('\\nKNN Optimized\\n')\n",
    "training_accuracy = np.mean(training_predictioin == y_train)\n",
    "test_accuracy = np.mean(prediction == y_test)\n",
    "\n",
    "print(\"\\nTrain Accuracy: \", training_accuracy)\n",
    "print(\"\\nTest Accuracy: \", test_accuracy)\n",
    "\n",
    "test_size = X_test.shape[0]\n",
    "test_no_correct = test_size  * test_accuracy\n",
    "\n",
    "print (\"\\nTest - No. Of Correct Predictions\", test_no_correct, \"/\", test_size)\n",
    "\n",
    "\n",
    "print(\"\\nTest Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, prediction))\n",
    "\n",
    "\n",
    "precision_test = precision_score(y_test, prediction,average='weighted') \n",
    "print(\"\\nTest Precision = %f\" % precision_test)\n",
    "\n",
    "recall_test = recall_score(y_test, prediction,average='weighted')\n",
    "print(\"Test Recall = %f\" % recall_test)\n",
    "\n",
    "\n",
    "f1_test = f1_score(y_test, prediction,average='weighted')\n",
    "print(\"Test F1 Score = %f\" % f1_test)\n",
    "\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparamater Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "cv = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=KNeighborsClassifier(), n_jobs=4,\n",
       "             param_grid={'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
       "                         'metric': ['manhattan', 'minkowski', 'euclidean'],\n",
       "                         'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
       "                         'weights': ['uniform', 'distance']},\n",
       "             scoring='accuracy', verbose=True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "f1_scorer = make_scorer(f1_score, pos_label= '1')\n",
    "param_grid = {\n",
    "    'metric':['manhattan', 'minkowski', 'euclidean'],\n",
    "    'n_neighbors':[1,2,3,4,5,6,7,8,9,10],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    \n",
    "}\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "grid_knn = GridSearchCV(knn, param_grid, scoring = 'accuracy', cv = 5, n_jobs = 4, verbose = True)\n",
    "grid_knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score (accuracy): 0.969192\n",
      "Optimal Hyperparameter Values:  {'algorithm': 'auto', 'metric': 'manhattan', 'n_neighbors': 10, 'weights': 'distance'}\n",
      "Worst Hyperparameter Valeus:  {'algorithm': 'auto', 'metric': 'minkowski', 'n_neighbors': 2, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "knn_best_params = grid_knn.best_params_\n",
    "knn_results = pd.DataFrame(grid_knn.cv_results_)\n",
    "worst_score = knn_results.loc[np.argmax(knn_results.rank_test_score)]\n",
    "worst_score_params = worst_score.params\n",
    "print(\"Best Score (accuracy): %f\" % grid_knn.best_score_)\n",
    "print(\"Optimal Hyperparameter Values: \", knn_best_params)\n",
    "print(\"Worst Hyperparameter Valeus: \", worst_score_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KNN Optimized\n",
      "\n",
      "\n",
      "Train Accuracy:  1.0\n",
      "\n",
      "Test Accuracy:  0.9733777038269551\n",
      "\n",
      "Test - No. Of Correct Predictions 585.0 / 601\n",
      "\n",
      "Test Confusion Matrix:\n",
      "[[ 53  11]\n",
      " [  5 532]]\n",
      "\n",
      "Test Precision = 0.972719\n",
      "Test Recall = 0.973378\n",
      "Test F1 Score = 0.972797\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.83      0.87        64\n",
      "           1       0.98      0.99      0.99       537\n",
      "\n",
      "    accuracy                           0.97       601\n",
      "   macro avg       0.95      0.91      0.93       601\n",
      "weighted avg       0.97      0.97      0.97       601\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn2 = KNeighborsClassifier(metric = 'manhattan', n_neighbors = 10, weights = 'distance')\n",
    "knn2.fit(X_train, y_train)\n",
    "prediction = knn2.predict(X_test)\n",
    "training_predictioin = knn2.predict(X_train)\n",
    "\n",
    "print('\\nKNN Optimized\\n')\n",
    "training_accuracy = np.mean(training_predictioin == y_train)\n",
    "test_accuracy = np.mean(prediction == y_test)\n",
    "\n",
    "print(\"\\nTrain Accuracy: \", training_accuracy)\n",
    "print(\"\\nTest Accuracy: \", test_accuracy)\n",
    "\n",
    "test_size = X_test.shape[0]\n",
    "test_no_correct = test_size  * test_accuracy\n",
    "\n",
    "print (\"\\nTest - No. Of Correct Predictions\", test_no_correct, \"/\", test_size)\n",
    "\n",
    "\n",
    "print(\"\\nTest Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, prediction))\n",
    "\n",
    "\n",
    "precision_test = precision_score(y_test, prediction,average='weighted') \n",
    "print(\"\\nTest Precision = %f\" % precision_test)\n",
    "\n",
    "recall_test = recall_score(y_test, prediction,average='weighted')\n",
    "print(\"Test Recall = %f\" % recall_test)\n",
    "\n",
    "\n",
    "f1_test = f1_score(y_test, prediction,average='weighted')\n",
    "print(\"Test F1 Score = %f\" % f1_test)\n",
    "\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R^2 set score: 0.98\n",
      "Test R^2 set score: 0.97\n",
      "\n",
      "Logistic Regression Base\n",
      "\n",
      "R squared score: 0.6502560521415269 \n",
      "Root Mean Squared Error: 0.033277870216306155 \n",
      "Mean Absolute Error 0.033277870216306155\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "logreg_base = LogisticRegression()\n",
    "logreg_base.fit(X_train, y_train)\n",
    "prediction = logreg_base.predict(X_test)\n",
    "print(\"Training R^2 set score: {:.2f}\".format(logreg_base.score(X_train, y_train)))\n",
    "print(\"Test R^2 set score: {:.2f}\".format(logreg_base.score(X_test, y_test)))\n",
    "\n",
    "r2 = r2_score(y_test , prediction)\n",
    "RMSE = mean_squared_error(y_test, prediction)\n",
    "MAE = mean_absolute_error(y_test, prediction)\n",
    "print(\"\\nLogistic Regression Base\")\n",
    "print('\\nR squared score:', r2, '\\nRoot Mean Squared Error:', RMSE, '\\nMean Absolute Error', MAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparamater Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1600 candidates, totalling 8000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  68 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=4)]: Done 2556 tasks      | elapsed:   18.9s\n",
      "[Parallel(n_jobs=4)]: Done 5140 tasks      | elapsed:   49.8s\n",
      "[Parallel(n_jobs=4)]: Done 7940 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=4)]: Done 8000 out of 8000 | elapsed:  1.6min finished\n",
      "C:\\Users\\scott\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\scott\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(), n_jobs=4,\n",
       "             param_grid={'C': array([1.00000000e-04, 2.63665090e-04, 6.95192796e-04, 1.83298071e-03,\n",
       "       4.83293024e-03, 1.27427499e-02, 3.35981829e-02, 8.85866790e-02,\n",
       "       2.33572147e-01, 6.15848211e-01, 1.62377674e+00, 4.28133240e+00,\n",
       "       1.12883789e+01, 2.97635144e+01, 7.84759970e+01, 2.06913808e+02,\n",
       "       5.45559478e+02, 1.43844989e+03, 3.79269019e+03, 1.00000000e+04]),\n",
       "                         'max_iter': [100, 1000, 2500, 5000],\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
       "                         'solver': ['lbfgs', 'newton-cg', 'liblinear', 'sag',\n",
       "                                    'saga']},\n",
       "             scoring='neg_root_mean_squared_error', verbose=True)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "param_grid_log = {\n",
    "        'penalty':['l1', 'l2', 'elasticnet', 'none'],\n",
    "        'C': np.logspace(-4,4,20),\n",
    "        'solver' : ['lbfgs', 'newton-cg', 'liblinear', 'sag', 'saga'],\n",
    "        'max_iter': [100, 1000, 2500, 5000]\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "log_grid = GridSearchCV(logreg, param_grid = param_grid_log, scoring = 'neg_root_mean_squared_error', verbose = True, cv=5, n_jobs=4)\n",
    "log_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Printing out the Best + Worst Performing Paramaters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score (neg_root_mean_squared_error): -0.163087\n",
      "Optimal Hyperparameter Values:  {'C': 0.23357214690901212, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "Worst Hyperparameter Valeus:  {'C': 0.0001, 'max_iter': 100, 'penalty': 'l1', 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "log_best_params = log_grid.best_params_\n",
    "log_results = pd.DataFrame(log_grid.cv_results_)\n",
    "worst_score = log_results.loc[np.argmax(log_results.rank_test_score)]\n",
    "worst_score_params = worst_score.params\n",
    "print(\"Best Score (neg_root_mean_squared_error): %f\" % log_grid.best_score_)\n",
    "print(\"Optimal Hyperparameter Values: \", log_best_params)\n",
    "print(\"Worst Hyperparameter Valeus: \", worst_score_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating the hyperparamater tuning on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R^2 set score: 0.98\n",
      "Test R^2 set score: 0.98\n",
      "\n",
      "Logistic Regression Optimized\n",
      "\n",
      "R squared score: 0.7872189768100548 \n",
      "Root Mean Squared Error: 0.019966722129783693 \n",
      "Mean Absolute Error 0.019966722129783693\n"
     ]
    }
   ],
   "source": [
    "logreg2 = LogisticRegression(C = 0.23357214690901212, max_iter = 1000, penalty = 'l2', solver = 'saga')\n",
    "logreg2.fit(X_train , y_train)\n",
    "prediction = logreg2.predict(X_test)\n",
    "print(\"Training R^2 set score: {:.2f}\".format(logreg2.score(X_train, y_train)))\n",
    "print(\"Test R^2 set score: {:.2f}\".format(logreg2.score(X_test, y_test)))\n",
    "\n",
    "r2 = r2_score(y_test , prediction)\n",
    "RMSE = mean_squared_error(y_test, prediction)\n",
    "MAE = mean_absolute_error(y_test, prediction)\n",
    "\n",
    "print(\"\\nLogistic Regression Optimized\")\n",
    "print('\\nR squared score:', r2, '\\nRoot Mean Squared Error:', RMSE, '\\nMean Absolute Error', MAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\SVM Base\n",
      "\n",
      "\n",
      "Train Accuracy:  0.9837635303913406\n",
      "\n",
      "Test Accuracy:  0.9633943427620633\n",
      "\n",
      "Test - No. Of Correct Predictions 579.0 / 601\n",
      "\n",
      "Test Confusion Matrix:\n",
      "[[ 51  13]\n",
      " [  9 528]]\n",
      "\n",
      "Test Precision = 0.962556\n",
      "Test Recall = 0.963394\n",
      "Test F1 Score = 0.962872\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.80      0.82        64\n",
      "           1       0.98      0.98      0.98       537\n",
      "\n",
      "    accuracy                           0.96       601\n",
      "   macro avg       0.91      0.89      0.90       601\n",
      "weighted avg       0.96      0.96      0.96       601\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "svm_base = SVC().fit(X_train, y_train)\n",
    "\n",
    "\n",
    "prediction = svm_base.predict(X_test)\n",
    "training_predictioin = svm_base.predict(X_train)\n",
    "\n",
    "print('\\SVM Base\\n')\n",
    "training_accuracy = np.mean(training_predictioin == y_train)\n",
    "test_accuracy = np.mean(prediction == y_test)\n",
    "\n",
    "print(\"\\nTrain Accuracy: \", training_accuracy)\n",
    "print(\"\\nTest Accuracy: \", test_accuracy)\n",
    "\n",
    "test_size = X_test.shape[0]\n",
    "test_no_correct = test_size  * test_accuracy\n",
    "\n",
    "print (\"\\nTest - No. Of Correct Predictions\", test_no_correct, \"/\", test_size)\n",
    "\n",
    "\n",
    "print(\"\\nTest Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, prediction))\n",
    "\n",
    "\n",
    "precision_test = precision_score(y_test, prediction,average='weighted') \n",
    "print(\"\\nTest Precision = %f\" % precision_test)\n",
    "\n",
    "recall_test = recall_score(y_test, prediction,average='weighted')\n",
    "print(\"Test Recall = %f\" % recall_test)\n",
    "\n",
    "\n",
    "f1_test = f1_score(y_test, prediction,average='weighted')\n",
    "print(\"Test F1 Score = %f\" % f1_test)\n",
    "\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparamater Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedShuffleSplit(n_splits=5, random_state=42, test_size=0.2,\n",
       "            train_size=None),\n",
       "             estimator=SVC(), n_jobs=4,\n",
       "             param_grid={'C': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
       "                         'gamma': [0.5, 1, 5, 10, 50, 100, 500, 1000],\n",
       "                         'kernel': ['linear', 'poly', 'rbf', 'sigmmoid']})"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C':[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],\n",
    "    'kernel':['linear', 'poly', 'rbf', 'sigmmoid'],\n",
    "    'gamma':[0.5, 1, 5, 10 ,50, 100, 500, 1000]\n",
    "}\n",
    "\n",
    "svm = SVC()\n",
    "grid_svm = GridSearchCV(svm, param_grid , scorer =f1_scorer, cv = cv, n_jobs = 4)\n",
    "grid_svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score (accuracy): 0.978794\n",
      "Optimal Hyperparameter Values:  {'C': 0.4, 'gamma': 0.5, 'kernel': 'linear'}\n",
      "Worst Hyperparameter Valeus:  {'C': 0.9, 'gamma': 1000, 'kernel': 'sigmmoid'}\n"
     ]
    }
   ],
   "source": [
    "svm_best_params = grid_svm.best_params_\n",
    "svm_results = pd.DataFrame(grid_svm.cv_results_)\n",
    "worst_score = svm_results.loc[np.argmax(svm_results.rank_test_score)]\n",
    "worst_score_params = worst_score.params\n",
    "print(\"Best Score (accuracy): %f\" % grid_svm.best_score_)\n",
    "print(\"Optimal Hyperparameter Values: \", svm_best_params)\n",
    "print(\"Worst Hyperparameter Valeus: \", worst_score_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\SVM Optimized\n",
      "\n",
      "\n",
      "Train Accuracy:  0.9804329725228976\n",
      "\n",
      "Test Accuracy:  0.9633943427620633\n",
      "\n",
      "Test - No. Of Correct Predictions 579.0 / 601\n",
      "\n",
      "Test Confusion Matrix:\n",
      "[[ 52  12]\n",
      " [ 10 527]]\n",
      "\n",
      "Test Precision = 0.962932\n",
      "Test Recall = 0.963394\n",
      "Test F1 Score = 0.963138\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.83        64\n",
      "           1       0.98      0.98      0.98       537\n",
      "\n",
      "    accuracy                           0.96       601\n",
      "   macro avg       0.91      0.90      0.90       601\n",
      "weighted avg       0.96      0.96      0.96       601\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm2 = SVC(C = 0.4, gamma = 0.5, kernel = 'linear')\n",
    "svm2.fit(X_train, y_train)\n",
    "prediction = svm2.predict(X_test)\n",
    "training_predictioin = svm2.predict(X_train)\n",
    "\n",
    "print('\\SVM Optimized\\n')\n",
    "training_accuracy = np.mean(training_predictioin == y_train)\n",
    "test_accuracy = np.mean(prediction == y_test)\n",
    "\n",
    "print(\"\\nTrain Accuracy: \", training_accuracy)\n",
    "print(\"\\nTest Accuracy: \", test_accuracy)\n",
    "\n",
    "test_size = X_test.shape[0]\n",
    "test_no_correct = test_size  * test_accuracy\n",
    "\n",
    "print (\"\\nTest - No. Of Correct Predictions\", test_no_correct, \"/\", test_size)\n",
    "\n",
    "\n",
    "print(\"\\nTest Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, prediction))\n",
    "\n",
    "\n",
    "precision_test = precision_score(y_test, prediction,average='weighted') \n",
    "print(\"\\nTest Precision = %f\" % precision_test)\n",
    "\n",
    "recall_test = recall_score(y_test, prediction,average='weighted')\n",
    "print(\"Test Recall = %f\" % recall_test)\n",
    "\n",
    "\n",
    "f1_test = f1_score(y_test, prediction,average='weighted')\n",
    "print(\"Test F1 Score = %f\" % f1_test)\n",
    "\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No real change in F1 or even accuracy between the hyperparamter scaling. \n",
    "Default SVC \n",
    "- Gamma = \"Scale\" \n",
    "    - this is equal to 1/(number of features * X.varriance) \n",
    "- Kernal = rbf\n",
    "- C = 1.0 \n",
    "\n",
    "\n",
    "Hyperparamaters \n",
    "\n",
    "\n",
    "- Gamma = 0.4\n",
    "- Kernal = Linear\n",
    "- C = 0.4 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
